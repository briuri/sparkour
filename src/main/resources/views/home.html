<!doctype html>
<html xmlns:th="http://www.thymeleaf.org" lang="en">
<head th:replace="~{shared :: head}"></head>
<body>
<script type="text/javascript">
    $(document).ready(function() {
        $("div.expand").click(
            function() {
                $(this).hide("fast");
                $(this).next().show("fast");
            });
    });
</script>
<div id="layoutOuterPosition">
    <a href="/"><div id="layoutHeaderRow">Sparkour</div></a>
    <div th:replace="~{shared :: menubar }"></div>
    <div id="layoutContent">
        <div id="layoutInnerContent">
            <h1 th:if="${title != 'Home'}" th:text="${title}"></h1>
            <!--/* ------------------------------------------------- */-->
            <h1>Sparkour</h1>

            <img th:src="@{images/logo-256.png}" width="160" height="160" title="Sparkour" align="right" />

            <!-- Description locations: index.jsp, header.jspf, LICENSE.txt, Issues -->
            <p>Sparkour is an open-source collection of programming recipes for <a href="https://spark.apache.org/">Apache Spark</a>.
                Designed as an efficient way to navigate the intricacies of the Spark ecosystem,
                Sparkour aims to be an approachable, understandable, and actionable cookbook for distributed data processing.</p>

            <p>Sparkour delivers extended tutorials for developers new to Spark as well as shorter, standalone recipes
                that address common developer needs in Java, Python, R, and Scala. The entire trove is
                <a href="/license">licensed</a> under the Apache License 2.0.</p>

            <h2>What's New? <a href="/files/atom.xml"><img th:src="@{images/atom.png}" width="20" height="20" title="Atom Feed" /></a></h2>

            <div id="newsFeed">
                <div class="newsUpdate">
                    <span class="newsDate">2020-03-07</span> All recipes have been updated and tested against Spark 2.4.5.
                </div>
                <div class="newsUpdate">
                    <span class="newsDate">2019-10-20</span>
                    <div th:replace="~{shared :: recipeLink('configuring-s3', '', ${recipeTitles['configuring-s3']}) }"></div> and
                    <div th:replace="~{shared :: recipeLink('using-s3', '', ${recipeTitles['using-s3']}) }"></div>
                    have been updated to reflect the deprecation of the <span class="rCW">s3n</span> protocol in favor of <span class="rCW">s3a</span>.
                </div>
                <div class="newsUpdate">
                    <span class="newsDate">2019-10-19</span> All recipes have been updated and tested against Spark 2.4.4.
                </div>
                <div class="newsUpdate">
                    <span class="newsDate">2019-05-30</span> All recipes have been updated and tested against Spark 2.4.3.
                </div>
                <div id="newsFeedControl" class="expand"><a href="#" onClick="return false;">more...</a></div>
                <div id="oldNews" class="hidden">
                    <div class="newsUpdate">
                        <span class="newsDate">2019-01-22</span>
                        <div th:replace="~{shared :: recipeLink('submitting-applications', '', ${recipeTitles['submitting-applications']}) }"></div>
                        has been updated with instructions for installing Python 3. All Python recipes have been tested against Python 3.6.7.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2019-01-06</span> Happy New Year! All recipes have been updated and tested against Spark 2.4.0. 
                        I have also incorporated some behind-the-scenes automation to streamline regression testing and make it easier for me 
                        to stay in sync with future Spark releases.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2018-05-27</span> All recipes have been updated and tested against Spark 2.3.0 and Scala 2.11.12.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2017-08-05</span> All recipes have been updated and tested against Spark 2.2.0.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2017-05-29</span> All recipes have been updated and tested against Spark 2.1.1 and Scala 2.11.11.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-10-09</span> All recipes have been updated and tested against Spark 2.0.1.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-09-24</span>
                        <div th:replace="~{shared :: recipeLink('understanding-sparksession', '', ${recipeTitles['understanding-sparksession']}) }"></div>
                        introduces the new <span class="rCW">SparkSession</span> class from Spark 2.0, which provides a unified entry point
                        for all of the various Context classes previously found in Spark 1.x.                        
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-09-22</span>
                        <div th:replace="~{shared :: recipeLink('installing-zeppelin', '', ${recipeTitles['installing-zeppelin']}) }"></div>
                        explains how to install Apache Zeppelin and configure it to work with Spark. Interactive notebooks
                        such as Zeppelin make it easier for analysts (who may not be software developers) to harness the power of Spark
                        through iterative exploration and built-in visualizations.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-09-21</span>
                        Website statistics prove that developers love Sparkour (except on the weekends). Thanks for your continued support!<br />
                        <img th:src="@{images/stats-160921.png}" width="589" height="240" title="Visitor Stats" class="diagram border" />
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-09-20</span> All recipes have been updated to use the new features available in Spark 2.0.0, 
                        such as the <span class="rCW">SparkSession</span> and the new Accumulator API. I will focus exclusively on Spark 2.x 
                        in future recipes, as that is the release most in need of solid documentation.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-06-28</span> All recipes have been updated and tested against Spark 1.6.2.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-05-07</span>
                        <div th:replace="~{shared :: recipeLink('aggregating-accumulators', '', ${recipeTitles['aggregating-accumulators']}) }"></div>
                        explains how to use accumulators to aggregate results in a Spark application.
                        Accumulators provide a safe way for multiple Spark workers to contribute information to
                        a shared variable, which can then be read by the application driver.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-05-04</span>
                        <div th:replace="~{shared :: recipeLink('controlling-schema', '', ${recipeTitles['controlling-schema']}) }"></div>
                        demonstrates different strategies for defining the schema of a DataFrame built from various data sources (using
                        RDD and JSON as examples). Schemas can be inferred from metadata or the data itself, or programmatically specified in advance
                        in your application.                        
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-04-14</span>
                        <div th:replace="~{shared :: recipeLink('broadcast-variables', '', ${recipeTitles['broadcast-variables']}) }"></div>
                        explains how to use broadcast variables to distribute immutable reference data across a Spark cluster. Using
                        broadcast variables can improve performance by reducing the amount of network traffic and data serialization required
                        to execute your Spark application.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-04-13</span>
                        <div th:replace="~{shared :: recipeLink('s3-vpc-endpoint', '', ${recipeTitles['s3-vpc-endpoint']}) }"></div>
                        shows how to set up a VPC Endpoint for Amazon S3, which allows your Spark cluster to interact with S3 resources from a private subnet
                        without a Network Address Translation (NAT) instance or Internet Gateway.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-04-07</span> All recipes have been updated and tested against Spark 1.6.1.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-29</span>
                        <div th:replace="~{shared :: recipeLink('building-maven', '', ${recipeTitles['building-maven']}) }"></div>
                        covers the use of Apache Maven to build and bundle Spark applications
                        written in Java or Scala. It focuses very narrowly on a subset of commands relevant to Spark applications, including
                        managing library dependencies, packaging, and creating an assembly JAR file.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-26</span>
                        <div th:replace="~{shared :: recipeLink('using-sql-udf', '', ${recipeTitles['using-sql-udf']}) }"></div>
                         demonstrates how to query Spark DataFrames with Structured Query Language (SQL). The Spark SQL library
                        supports SQL as an alternate way to work with DataFrames that is compatible with the code-based approach discussed in
                        the recipe,
                        <div th:replace="~{shared :: recipeLink('working-dataframes', '', ${recipeTitles['working-dataframes']}) }"></div>
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-24</span>
                        <div th:replace="~{shared :: recipeLink('using-jdbc', '', ${recipeTitles['using-jdbc']}) }"></div>
                        shows how Spark DataFrames can be read from or written to relational database tables with Java Database Connectivity (JDBC).
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-17</span>
                        <div th:replace="~{shared :: recipeLink('building-sbt', '', ${recipeTitles['building-sbt']}) }"></div>
                        covers the use of SBT (Simple Build Tool or, sometimes, Scala Build Tool) to build and bundle Spark applications
                        written in Java or Scala. It focuses very narrowly on a subset of commands relevant to Spark applications, including
                        managing library dependencies, packaging, and creating an assembly JAR file with the <span class="rCW">sbt-assembly</span> plugin.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-15</span>
                        <div th:replace="~{shared :: recipeLink('submitting-applications', '', ${recipeTitles['submitting-applications']}) }"></div>
                        has been updated to include examples in Java, R, and Scala as well as the original Python.                        
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-11</span>
                        <div th:replace="~{shared :: recipeLink('working-dataframes', '', ${recipeTitles['working-dataframes']}) }"></div>
                        provides a straightforward introduction to the Spark DataFrames API. It uses common DataFrames operators to explore and transform raw data
                        from the 2016 Democratic Primary in Virginia.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-06</span>                         
                        <div th:replace="~{shared :: recipeLink('using-s3', '', ${recipeTitles['using-s3']}) }"></div>
                        provides the steps needed to securely connect an Apache Spark cluster running on Amazon EC2	to data stored in Amazon S3.
                        It contains instructions for both the classic <span class="rCW">s3n</span> protocol and the newer, but still maturing,
                        <span class="rCW">s3a</span> protocol.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-05</span>
                        <div th:replace="~{shared :: recipeLink('configuring-s3', '', ${recipeTitles['configuring-s3']}) }"></div>
                        provides the steps needed to securely expose data in Amazon S3 for consumption by a Spark application.
                        The resultant configuration works with both supported S3 protocols in Spark: the classic <span class="rCW">s3n</span>
                        protocol and the newer, but still maturing, <span class="rCW">s3a</span> protocol.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-04</span>
                        <div th:replace="~{shared :: recipeLink('spark-ec2', '', ${recipeTitles['spark-ec2']}) }"></div>
                        describes how to automatically launch, start, stop, or destroy a Spark cluster running in Amazon EC2.
                        It steps through the pre-launch configuration, explains the script's most common parameters, and points out where
                        specific parameters can be found in the AWS Management Console.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-03-01</span>
                        Welcome to Sparkour!
                        To kick things off, I have released 5 sequential <a href="/recipes">tutorials</a>, which should give you a solid foundation for mastering Spark.
                        My long-term goal is to publish a few new recipes each month until the end of time. Help me improve Sparkour
                        by submitting bugs and improvement suggestions on the <a href="https://ddmsence.atlassian.net/projects/SPARKOUR/summary">Issues</a> page.
                    </div>
                    <div class="newsUpdate">
                        <span class="newsDate">2016-02-15</span> The idea for Sparkour was conceived during the President's Day ice storm.
                    </div>
                </div>
            </div>

            <h2>About the Author</h2>

            <p><img th:src="@{images/author.jpg}" width="120" height="120" title="BU" class="border" align="left" />
                <a href="https://www.linkedin.com/in/urizone">Brian Uri!</a> has over 20 years of experience in software engineering, proposal writing, and government data standards,
                with relevant certifications in Amazon Web Services and Apache Hadoop.</p>

            <p>Sparkour was conceived in February 2016 as a way for Brian to learn Apache Spark while scratching an itch to create more open-source software.
                Brian is also the creator of the open-source library, <a href="https://ddmsence.urizone.net/">DDMSence</a>.</p>
            <!--/* ------------------------------------------------- */-->
        </div>
        <div th:replace="~{shared :: footer }"></div>
    </div>
</div>
</body>
</html>
